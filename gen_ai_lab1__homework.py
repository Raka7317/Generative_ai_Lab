# -*- coding: utf-8 -*-
"""Gen_ai_lab1_ homework.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yWPKZg4pqiECZG0lJCOV6N1EQZoUnBxr
"""

from collections import Counter  # To count occurrences of words
import re  # For pattern matching

text = "AI is transforming the world. AI technologies are shaping the future."

# Convert to lowercase and extract words using regex \w+ (letters/digits)
words = re.findall(r'\w+', text.lower())

# Count each word
freq = Counter(words)

print(freq)  # Print frequency dictionary

from nltk import bigrams  # To generate pairs of consecutive words
from collections import Counter
import re

text = "Data science is fun and data science is powerful when used properly."

# Extract words in lowercase
words = re.findall(r'\w+', text.lower())

# Create list of word pairs
bigram_list = list(bigrams(words))

# Count each bigram
freq = Counter(bigram_list)

print(freq.most_common(1))  # Print the most frequent bigram

def classify_sentence(sentence):
    # Check if the sentence ends with a question mark
    return "Question" if sentence.strip().endswith("?") else "Statement"

print(classify_sentence("How are you?"))  # Should return Question
print(classify_sentence("I am fine."))  # Should return Statement

import re

text = "Contact us at support@gmail.com or admin@vit.ac.in for details."

# Regex to match email pattern
emails = re.findall(r'[\w\.-]+@[\w\.-]+\.\w+', text)

print(emails)  # Print found email IDs

text = "Hello AI 2025!"  # Sample text

total_chars = len(text)  # Count all characters

# Count digits, uppercase and lowercase using built-in string functions
digits = sum(ch.isdigit() for ch in text)
upper = sum(ch.isupper() for ch in text)
lower = sum(ch.islower() for ch in text)

print("Total:", total_chars, "Digits:", digits, "Upper:", upper, "Lower:", lower)

stopwords = ["the", "is", "are", "a", "an", "and", "of", "to", "in", "on"]  # Common words to remove
text = "The AI Revolution is changing the world of technology in a massive way."

# Split into words + convert to lowercase
words = [w.lower() for w in text.split()]

# Keep only words not in stopword list
filtered = [w for w in words if w not in stopwords]

print(filtered)  # Print filtered useful words

def similarity(s1, s2):
    # Convert both sentences to sets of lowercase words
    set1, set2 = set(s1.lower().split()), set(s2.lower().split())

    common = len(set1 & set2)  # Words present in both (intersection)
    total = len(set1 | set2)   # All unique words (union)

    return common / total  # Overlap score

print(similarity("I love machine learning", "machine learning is fun"))

text = "Machine learning makes computers learn from data".split()  # Split text into words
n = 3  # Chunk size

# Take 3 consecutive words at a time
chunks = [' '.join(text[i:i+n]) for i in range(len(text)-n+1)]

print(chunks)

positive = ["good", "great", "awesome", "love"]  # Positive words list
negative = ["bad", "poor", "terrible", "hate"]  # Negative words list

def sentiment(sentence):
    words = sentence.lower().split()  # Convert to lowercase words

    # Count pos words and subtract neg words â†’ sentiment score
    score = sum(w in positive for w in words) - sum(w in negative for w in words)

    # Decide based on score
    return "Positive" if score > 0 else "Negative" if score < 0 else "Neutral"

print(sentiment("The movie was awesome"))
print(sentiment("I hate waiting"))
print(sentiment("It was a great experience"))

from collections import Counter
import re

stop = ["the", "is", "are", "a", "an", "and", "of", "to", "in", "on"]

text = "Machine learning is the future of AI and AI is transforming the world."
words = [w for w in re.findall(r'\w+', text.lower()) if w not in stop]
keywords = Counter(words).most_common(5)
print(keywords)

import re

def is_palindrome(sentence):
    # Remove all characters except letters/digits & convert lowercase
    s = re.sub(r'[^A-Za-z0-9]', '', sentence.lower())

    return s == s[::-1]  # Check if same when reversed

print(is_palindrome("Nurses run"))  # True
print(is_palindrome("Was it a car or a cat I saw"))  # True

import re

text = "AI is trending! #AI #MachineLearning #DeepLearning"

# Find all hashtags (# followed by letters/digits)
hashtags = re.findall(r'#\w+', text)

print(hashtags)

import re

text = "AI is the future and the future is AI"

# Extract words in lowercase
words = re.findall(r'\w+', text.lower())

total = len(words)      # Count all words
unique = len(set(words)) # Count unique words
diversity = unique / total  # Diversity score

print("Total:", total)
print("Unique:", unique)
print("Diversity:", round(diversity, 2))  # Print up to 2 decimal places