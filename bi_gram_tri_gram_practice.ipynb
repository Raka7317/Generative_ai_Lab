{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhYpRI8M5CQvfiV6AzcCwd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raka7317/Generative_ai_Lab/blob/main/bi_gram_tri_gram_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzXZGDDgosiD",
        "outputId": "b6da2955-b5af-4b96-e23b-1c58806ec7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean Text: data science is fun and data science is powerful\n",
            "Tokens: ['data', 'science', 'is', 'fun', 'and', 'data', 'science', 'is', 'powerful']\n",
            "\n",
            "Bigrams: [('data', 'science'), ('science', 'is'), ('is', 'fun'), ('fun', 'and'), ('and', 'data'), ('data', 'science'), ('science', 'is'), ('is', 'powerful')]\n",
            "Bigram Perplexity: 1.189207115002721\n",
            "\n",
            "Trigrams: [('data', 'science', 'is'), ('science', 'is', 'fun'), ('is', 'fun', 'and'), ('fun', 'and', 'data'), ('and', 'data', 'science'), ('data', 'science', 'is'), ('science', 'is', 'powerful')]\n",
            "Trigram Perplexity: 1.2190136542044754\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# -------------------------------\n",
        "# 1. TEXT PREPROCESSING\n",
        "# -------------------------------\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation & special characters\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 2. TOKENIZATION\n",
        "# -------------------------------\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 3. N-GRAM GENERATION\n",
        "# -------------------------------\n",
        "def generate_ngrams(tokens, n):\n",
        "    ngrams = []\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        ngrams.append(tuple(tokens[i:i+n]))\n",
        "    return ngrams\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 4. N-GRAM PROBABILITY\n",
        "# -------------------------------\n",
        "def calculate_ngram_probabilities(ngrams, lower_ngrams):\n",
        "    ngram_counts = Counter(ngrams)\n",
        "    lower_ngram_counts = Counter(lower_ngrams)\n",
        "\n",
        "    probabilities = {}\n",
        "    for ngram in ngram_counts:\n",
        "        prefix = ngram[:-1]   # (w1,w2) for trigram or (w1) for bigram\n",
        "        probabilities[ngram] = ngram_counts[ngram] / lower_ngram_counts[prefix]\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 5. PERPLEXITY CALCULATION\n",
        "# -------------------------------\n",
        "def calculate_perplexity(ngrams, probabilities):\n",
        "    N = len(ngrams)\n",
        "    log_prob_sum = 0\n",
        "\n",
        "    for ngram in ngrams:\n",
        "        prob = probabilities.get(ngram, 1e-10)  # avoid log(0)\n",
        "        log_prob_sum += math.log(prob)\n",
        "\n",
        "    perplexity = math.exp(-log_prob_sum / N)\n",
        "    return perplexity\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 6. MAIN EXECUTION\n",
        "# -------------------------------\n",
        "text = \"Data science is fun and data science is powerful\"\n",
        "\n",
        "# Preprocess\n",
        "clean_text = preprocess_text(text)\n",
        "\n",
        "# Tokenize\n",
        "tokens = tokenize(clean_text)\n",
        "\n",
        "# ---------- BIGRAM MODEL ----------\n",
        "bigrams = generate_ngrams(tokens, 2)\n",
        "unigrams = [(token,) for token in tokens]\n",
        "\n",
        "bigram_probs = calculate_ngram_probabilities(bigrams, unigrams)\n",
        "bigram_perplexity = calculate_perplexity(bigrams, bigram_probs)\n",
        "\n",
        "# ---------- TRIGRAM MODEL ----------\n",
        "trigrams = generate_ngrams(tokens, 3)\n",
        "bigram_prefixes = generate_ngrams(tokens, 2)\n",
        "\n",
        "trigram_probs = calculate_ngram_probabilities(trigrams, bigram_prefixes)\n",
        "trigram_perplexity = calculate_perplexity(trigrams, trigram_probs)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 7. OUTPUT\n",
        "# -------------------------------\n",
        "print(\"Clean Text:\", clean_text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "print(\"\\nBigrams:\", bigrams)\n",
        "print(\"Bigram Perplexity:\", bigram_perplexity)\n",
        "\n",
        "print(\"\\nTrigrams:\", trigrams)\n",
        "print(\"Trigram Perplexity:\", trigram_perplexity)\n"
      ]
    }
  ]
}